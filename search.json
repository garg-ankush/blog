[
  {
    "objectID": "wip/Job-skills/test.html",
    "href": "wip/Job-skills/test.html",
    "title": "LinkedIn Job Post Analysis",
    "section": "",
    "text": "import pandas as pd\nimport ast\nfrom helpers import get_top_counts\nimport plotly.express as px\n\ndef parse_list(s):\n    try:\n        return ast.literal_eval(s)\n    except:  # noqa: E722\n        return s\n\ndf = pd.read_csv(\"cleaned_up.csv\", converters={\n    'key_skills': parse_list,\n    'tech_stack': parse_list,\n    'languages': parse_list,\n    'strong_experience': parse_list\n})\n\ntest_df = pd.DataFrame([dict(get_top_counts(df['tech_stack']))]).T"
  },
  {
    "objectID": "wip/Job-skills/test.html#row",
    "href": "wip/Job-skills/test.html#row",
    "title": "LinkedIn Job Post Analysis",
    "section": "",
    "text": "import pandas as pd\nimport ast\nfrom helpers import get_top_counts\nimport plotly.express as px\n\ndef parse_list(s):\n    try:\n        return ast.literal_eval(s)\n    except:  # noqa: E722\n        return s\n\ndf = pd.read_csv(\"cleaned_up.csv\", converters={\n    'key_skills': parse_list,\n    'tech_stack': parse_list,\n    'languages': parse_list,\n    'strong_experience': parse_list\n})\n\ntest_df = pd.DataFrame([dict(get_top_counts(df['tech_stack']))]).T"
  },
  {
    "objectID": "wip/Job-skills/test.html#plotly",
    "href": "wip/Job-skills/test.html#plotly",
    "title": "LinkedIn Job Post Analysis",
    "section": "Plotly",
    "text": "Plotly\n\nfig = px.bar(test_df, title=\"Number of test\")\nfig.show()"
  },
  {
    "objectID": "wip/Job-skills/test.html#plotly-1",
    "href": "wip/Job-skills/test.html#plotly-1",
    "title": "LinkedIn Job Post Analysis",
    "section": "Plotly",
    "text": "Plotly\n\nimport plotly.express as px\nimport plotly.io as pio\ngapminder = px.data.gapminder()\ngapminder2007 = gapminder.query(\"year == 2007\")\nfig = px.scatter(gapminder2007, \n                 x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", \n                 size=\"pop\", size_max=60,\n                 hover_name=\"country\")\nfig.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ankush Garg - Personal Blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 20, 2024\n\n\nMonte Carlo Simulation for estimating π\n\n\nAnkush Garg\n\n\n\n\nFeb 9, 2023\n\n\nML-clerk, a simple way to store modeling results for data scientists\n\n\nAnkush Garg\n\n\n\n\nFeb 9, 2023\n\n\nDeploy your chatGPT-like app with Chainlit and AWS ECS\n\n\nAnkush Garg\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html",
    "href": "posts/Chainlit-deployment/index.html",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "",
    "text": "🔗💡Chainlit is an open-source Python package that allows you to create ChatGPT-like UIs on top of any Python code in just minutes! Visit the GitHub repo to get started!\nThis post is designed to guide you through deploying your Chainlit apps to AWS ECS.\nIn this tutorial, we’ll be using this sample example. Feel free to use your own application instead.\nPrerequisites:"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-1-create-an-aws-account-and-set-up-credentials",
    "href": "posts/Chainlit-deployment/index.html#step-1-create-an-aws-account-and-set-up-credentials",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 1: Create an AWS account and set up credentials 🚀 ",
    "text": "Step 1: Create an AWS account and set up credentials 🚀 \nFollow steps in this blog post by AWS to configure AWS CLI."
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-2-clone-the-repo---bypass-if-you-already-an-ongoing-chainlit-project",
    "href": "posts/Chainlit-deployment/index.html#step-2-clone-the-repo---bypass-if-you-already-an-ongoing-chainlit-project",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 2: Clone the repo - bypass if you already an ongoing chainlit project 🧫 ",
    "text": "Step 2: Clone the repo - bypass if you already an ongoing chainlit project 🧫 \ngit clone https://github.com/Chainlit/cookbook.git chainlit-cookbook\nNavigate to the app folder:\ncd chainlit-cookbook/aws-ecs-deployment"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-3-dockerfile",
    "href": "posts/Chainlit-deployment/index.html#step-3-dockerfile",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 3: Dockerfile 🐳 ",
    "text": "Step 3: Dockerfile 🐳 \n# Use an appropriate base image, e.g., python:3.10-slim\nFROM python:3.10-slim\n\n# Set environment variables (e.g., set Python to run in unbuffered mode)\nENV PYTHONUNBUFFERED 1\n\n# Set the working directory\nWORKDIR /app\n\n# Copy your application's requirements and install them\nCOPY requirements.txt /app/\n\nRUN pip install -r /app/requirements.txt\n\n# Copy your application code into the container\nCOPY . /app/\n\nEXPOSE 8080\n\nCMD [\"python\", \"-m\", \"chainlit\", \"run\", \"app.py\", \"-h\", \"--port\", \"8080\"]\n❗ If you’re on Mac M1, replace the first line in Dockerfile with FROM --platform=linux/amd64 python:3.9-slim\n\nOur app is exposed on port 8080. We’ll be using this port in multiple locations.&gt;"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-4-run-the-chainlit-app-locally",
    "href": "posts/Chainlit-deployment/index.html#step-4-run-the-chainlit-app-locally",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 4: Run the Chainlit app locally 🏡 ",
    "text": "Step 4: Run the Chainlit app locally 🏡 \n🚧 Make sure Docker Daemon is running.\nFirst, build the docker image and test that the app works locally.\ndocker build -t chainlit-app:latest .\nHere’s what it looks like for me.\n\nNow, let’s confirm that the image was built successfully.\ndocker images\n\nLet’s run the app locally and navigate to localhost:8080 🥂\ndocker run -p 8080:8080 chainlit:latest"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-5-create-ecr-and-push-the-image",
    "href": "posts/Chainlit-deployment/index.html#step-5-create-ecr-and-push-the-image",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 5: Create ECR and push the image 📌 ",
    "text": "Step 5: Create ECR and push the image 📌 \nLet’s head over to AWS ECR and create a repository where we’ll push our docker image to.\n\nOnce a repository is created, let’s push an image to it. Head over to the repository and click View push commands.\n\nLet’s follow the helper commands to push our image to the Chainlit-demo-app repository we just created.\n🚧 Note, we already created built an image to test the app locally. But that’s ok, let’s rebuild the image again to avoid confusion.\n\nAwesome, this is what it looks like on my end.\n\nLet’s see if we find the image on AWS.\n\n🚧 Take note of the image URI - we’ll need it later.\nGreat, our repository and our image is set. Let’s head over to ECS to create a service and a task."
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-6-create-task-definition-and-service-and-run-task",
    "href": "posts/Chainlit-deployment/index.html#step-6-create-task-definition-and-service-and-run-task",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 6: Create task definition and service and run task 🏃🏼‍♀️ ",
    "text": "Step 6: Create task definition and service and run task 🏃🏼‍♀️ \n\nCreate a new cluster\n\n\nClick create and we should see a new cluster chainlit-demo-app-cluster has been created for us.\n\n\nCreate a task definition\n\n\n🚧 Make sure the container port matches the port we exposed in the Dockerfile.\nLeave everything else as default and create our task definition.\n\n\n\nCreate a service\n\n\n\nWe should be good to create our service. Let’s hit it 👊🏼\n🚧 It may take a few minutes for the service to be ready.\nMap the ports correctly.\n❗ One last thing we need to do before our task is ready is to allow traffic to the right port. You may have these set up already but if not, set the ports so that you allow all incoming traffic to port 8080.\n\n\n\nYour task should be running at this point. Head over to the tasks tab of the chainlit-demo-app-service .\n\n\n🚧 Our app is exposed at this public IP: 52.204.71.81:8080"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-7-test-out-the-application",
    "href": "posts/Chainlit-deployment/index.html#step-7-test-out-the-application",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 7: Test out the application 💯 ",
    "text": "Step 7: Test out the application 💯 \nHead over to the public IP in the browser to see our app in action!"
  },
  {
    "objectID": "posts/Chainlit-deployment/index.html#step-8-ideas-for-next-steps",
    "href": "posts/Chainlit-deployment/index.html#step-8-ideas-for-next-steps",
    "title": "Deploy your chatGPT-like app with Chainlit and AWS ECS",
    "section": "Step 8: Ideas for next steps 🪜 ",
    "text": "Step 8: Ideas for next steps 🪜 \n\nWe have our app running on a weird public IP address - we can connect it to our own domain.\nLoad Balancer - Will give us a better performance and high availability.\nRight now our is not very secure. AWS Certificate Manager makes getting an SSL certificate relatively straightforward.\n\nI hope this helps the growing Chainlit community! Hit me up in the Chainlit Discord (ankushgarg) if you have any questions about the walkthrough.\nResources:\nDeploy to Fly.io\nDeploy to GCP"
  },
  {
    "objectID": "posts/ML-clerk/index.html",
    "href": "posts/ML-clerk/index.html",
    "title": "ML-clerk, a simple way to store modeling results for data scientists",
    "section": "",
    "text": "Python package here: ml-clerk\nWhat is ml-clerk?\nML-clerk, at its core, is a lightweight logging library that helps you keep track of performance, model parameters, timing (or whatever) throughout your data science experiment.\nI’m a data scientist. Why should I care?\nAs a data scientist you’re constantly running new experiments. As you run new experiments, you are recording your results (if not, you should be recording your results). ML clerk does exactly that. It reduces the inertia by automatically recording the results of your experiment, so you don’t have to worry about keeping track.\nOk now that I’m convinced, where does ml-clerk log stuff?\nML clerk has two places where it tracks things - excel or google sheets. Excel setup is easier, so start with that. For google sheets usage, see the link below.\n\nTraining a model - demo purposes only\n# Imports\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\ndataset = load_iris()\n\n# Define data\nX = dataset['data']\ny = dataset['target']\n\n# Train the model\nlogistic_regression_classifier = LogisticRegression()\nlogistic_regression_classifier.fit(X, y)\n\n# Make predictions\npredictions = logistic_regression_classifier.predict(X)\nprobabilities = logistic_regression_classifier.predict_proba(X)\n\n\nExcel usage\n#!/usr/bin/python\nfrom ml_clerk import Clerk\n\n# Set up the clerk with excel mode\nclerk = Clerk(excel_mode=True)\n\n# file_path refers to the excel workbook you want to record in, and the sheet name referes to the sheet\nFILE_PATH = 'hello_world.xlsx'\nSHEET_NAME = 'Sheet1'\n\nclerk.set_up(filepath=FILE_PATH, sheet_name=SHEET_NAME)\n\n### Record all the artifacts in one go\nclerk.record(predictions=predictions, probabilities=probabilities, model_parameters=logistic_regression_classifier.get_params())\n\n\nGoogle sheets usage\nfrom ml_clerk import Clerk\n\n# Set up the clerk with google sheets mode\n\nclerk = Clerk(google_sheets_mode=True)\n\n# file_path refers to the excel workbook you want to record in, and the sheet name refers to the sheet\nGOOGLE_SHEETS_FILE_PATH = '#your google sheets url'\nSHEET_NAME = '#your sheet name'\n\nclerk.set_up(file_path=GOOGLE_SHEETS_FILE_PATH, sheet_name=SHEET_NAME)\n\n# Record all the artifacts in one go\nclerk.record(\n            predictions=predictions,\n          probabilities=probabilities, \n            model_parameters=logistic_regression_classifier.get_params()\n)\nGoogle sheets permissions\n\nFollow this link for how to permission your Google account - py-gsheets.\nMake sure you enable the Google sheets API under the project in Google console.\nUpdate the .env with the path to token.json credentials file."
  },
  {
    "objectID": "posts/Monte-Carlo/index.html",
    "href": "posts/Monte-Carlo/index.html",
    "title": "Monte Carlo Simulation for estimating π",
    "section": "",
    "text": "Consider a square with side length 2, centered at the origin, with a circle of radius 1 inscribed within it.\nKey points:\n\nSquare area: 4 square units\nCircle area: π square units\n\nThe ratio of these areas is π/4."
  },
  {
    "objectID": "posts/Monte-Carlo/index.html#lets-run-the-simulation.",
    "href": "posts/Monte-Carlo/index.html#lets-run-the-simulation.",
    "title": "Monte Carlo Simulation for estimating π",
    "section": "Let’s run the simulation.",
    "text": "Let’s run the simulation.\n\n\nShow the code\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\n\n# Generate sample data\nn_frames = int(len(df) / 10)\nN = 10\n\n# Create a DataFrame with cumulative data\ndf_list = []\nfor i in range(1, n_frames + 1):\n    df_temp = pd.DataFrame({\n        'x': df['x'][:i*N], \n        'y': df['y'][:i*N],\n        'in_circle': df['in_circle'][:i*N],\n        'rolling_est': df['rolling_est'][:i*N],\n        'Iteration': i\n    })\n    df_list.append(df_temp)\n\ndf_with_iterations_for_viz = pd.concat(df_list, ignore_index=True)\n\n# Create the animated scatter plot\nfig = px.scatter(\n    df_with_iterations_for_viz,\n    x='x',\n    y='y',\n    animation_frame='Iteration',\n    range_x=[-2, 2], range_y=[-1, 1]\n    ) \n\n# Add a circle\nfig = fig.add_shape(type=\"circle\",\n    xref=\"x\", yref=\"y\",\n    x0=-1, y0=-1, x1=1, y1=1,\n    line_color=\"red\",\n)\n\n# Add a square\nfig = fig.add_shape(type=\"rect\",\n    xref=\"x\", yref=\"y\",\n    x0=-1, y0=-1,\n    x1=1, y1=1,\n    line_color=\"Black\"\n)\n\n# Fix axes\nfig = fig.update_yaxes(\n    scaleanchor = \"x\",\n    scaleratio = 1,\n)\n\n# Update layout for better appearance\nfig = fig.update_layout(\n    title='Cumulative Scatter Plot Animation',\n    xaxis_title='X Axis',\n    yaxis_title='Y Axis',\n    showlegend=False\n)\n\nfig.show()"
  },
  {
    "objectID": "posts/Monte-Carlo/index.html#rolling-estimate-of-π-converges-over-many-iterations.",
    "href": "posts/Monte-Carlo/index.html#rolling-estimate-of-π-converges-over-many-iterations.",
    "title": "Monte Carlo Simulation for estimating π",
    "section": "Rolling estimate of π converges over many iterations.",
    "text": "Rolling estimate of π converges over many iterations.\n\n\nShow the code\nimport pandas as pd\nimport plotly.express as px\n\n# Assuming df is your DataFrame\n# Calculate the rolling average\nwindow_size = 20\nrolling_avg = df['rolling_est'].rolling(window=window_size).mean()\n\n# Create a new DataFrame to store the rolling averages\nrolling_avg_df = df.copy()\nrolling_avg_df['rolling_avg'] = rolling_avg\n\n# Drop NaN values that were created by the rolling mean\nrolling_avg_df = rolling_avg_df.dropna()\n\n# Prepare the DataFrame for visualization\nn_frames = int(len(rolling_avg_df) / 10)\nN = 10\n\ndf_list = []\nfor i in range(1, n_frames + 1):\n    df_temp = pd.DataFrame({\n        'index': rolling_avg_df.index[:i*N],  # Use the index for x-axis\n        'rolling_avg': rolling_avg_df['rolling_avg'][:i*N],\n        'Iteration': i\n    })\n    df_list.append(df_temp)\n\n# Combine all the frames into one DataFrame\nrolling_avg_with_iterations = pd.concat(df_list, ignore_index=True)\n\n# Create the animated line plot with fixed x-axis\nfig = px.scatter(\n    rolling_avg_with_iterations,\n    x='index',\n    y='rolling_avg',\n    animation_frame='Iteration',\n    range_x=[0, len(rolling_avg_df)],  # Fix the x-axis range to cover the entire index range\n    range_y=[1, 3.5],\n    title='Animated Rolling Average Estimation Time Series',\n    labels={'index': 'DataFrame Index', 'rolling_avg': 'Rolling Average Estimation'},\n)\n\nfig = fig.add_shape(\n        type='line',\n        x0=0,\n        y0=3.1415926535897932,\n        x1=3000,\n        y1=3.1415926535897932,\n        line=dict(\n            color='Red',\n        )\n)\n\n# Update layout to improve appearance\nfig = fig.update_traces(line=dict(width=2))\nfig = fig.update_layout(\n    updatemenus=[{\n        'buttons': [\n            {\n                'args': [None, {'frame': {'duration': 50, 'redraw': True}, 'fromcurrent': True}],\n                'label': 'Play',\n                'method': 'animate'\n            },\n            {\n                'args': [[None], {'frame': {'duration': 0, 'redraw': True}, 'mode': 'immediate', 'transition': {'duration': 0}}],\n                'label': 'Pause',\n                'method': 'animate'\n            }\n        ],\n        'direction': 'left',\n        'pad': {'r': 10, 't': 87},\n        'showactive': False,\n        'type': 'buttons',\n        'x': 0.1,\n        'xanchor': 'right',\n        'yanchor': 'top'\n    }]\n)\nfig.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi there, it’s Ankush 👋\n🔭 I’m currently working on getting my Master’s in Data Science at UC Berkeley\n🌱 I’m currently thinking how to apply my data science skills to price transparency in healthcare\n💬 I write sometimes on my blog\n📫 I’m reachable on linkedIn or by email at ankush-garg@berkeley.edu"
  }
]